---
title: "Klasyfikacja ozonu" 
author: 
        - Jakub Naporowski 
        - Informatyka Geoprzestrzenna
        - "423583"
date: today 
format: 
  html:
    toc: true
    toc-depth: 3
    toc-location: right
    toc-title: Spis Treści
    number-sections: true
    number-depth: 3
    html-math-method: katex
    code-tools: true
    code-block-bg: true
    code-fold: show
    code-summary: "Show and hide code"
    link-external-icon: true
    link-external-newwindow: true
    smooth-scroll: true
    self-contained: true
    theme: 
        dark: solar
        light: flatly
    fontsize: 1.0em
    linestretch: 1.3
    fig-align: center
execute: 
  echo: true
  error: false
  warning: false
  output: true
editor_options: 
  chunk_output_type: console
---

# Biblioteki

```{r}
library(tidymodels) 
library(tidyverse)
library(skimr) 
library(GGally) 
library(openair) 
library(glmnet)
```

# Przygotowanie danych

## Zaczniemy do wybrania roku i przygotowania danych

```{r}
air <- mydata |> selectByDate(year = 2004) 
air |> skim()

air <- air |> na.omit()
```

## Korelacja między nox i no2. Widać dużą zależność.

```{r}
set.seed(222)
air[sample(1:nrow(air), size = 300, replace = F),] |> 
  select(nox, no2) |> 
  ggpairs()
```

## Stężenia ozonu
```{r}
air |>    
  ggplot(aes(date, o3)) +     
  geom_line() +     
  theme_bw()
```

## Dodanie klasyfikacji
```{r}
air <-
  air |>
  mutate(ozone = cut(
    o3,
    breaks = c(-0.1, 10, 43),
    labels = c("Niskie", "Wysokie")
  ))
air |> count(ozone)
```

## Przygotowane dane
```{r}
air |>
  skimr::skim()
```

# Model klasyfikacji

## Podział danych
```{r}
set.seed(222)
data_split <- initial_split(air, strata = ozone)
train_data <- training(data_split)
test_data <- testing(data_split)
```

## Tworzenie przepisu

### Pierwszy przepis
``` {r}
air_recipe <- recipe(ozone ~ ., data = train_data) |>
  update_role(date, new_role="Data") |>
  step_date(date, features = c("month", "doy")) |>
  step_time(date, features = c("hour")) |>
  # step_normalize(all_numeric_predictors()) |>
  step_YeoJohnson(all_numeric_predictors(), -all_outcomes()) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors()) |>
  step_corr(all_numeric_predictors(), threshold = 0.9)
```

Pierwszy przepis miał wiele błędów, jego wyniki w modelu były zbyt doskonałe, krzywa roc wyglądała jak kwadrat, macierz błędów nie miała żadnych błędów, dlatego po wielu próbach dostrajania zrezygnowałem z tego przepisu. Doszedłem do wniosku że powinienem pozbyć się kolumny o3, gdyż za model za bardzo sie na niej opierał.

### Poprawiony przepis

Myślę, że więcej zmiennych zasługuje na role = ID

``` {r}
air_recipe_o3 <- recipe(ozone ~ ., data = train_data) |> 
  step_rm(o3) |> 
  update_role(date, new_role="Data") |> 
  step_date(date, features = c("month", "doy")) |> 
  step_YeoJohnson(all_numeric_predictors(), -all_outcomes()) |> # wartość roc jest lepsza o 0.009
  step_time(date, features = c("hour")) |> 
  # step_normalize(all_numeric_predictors()) |> # normalizacja nic nie zmienia
  step_dummy(all_nominal_predictors()) |> 
  step_zv(all_predictors())
```

```{r}
air_recipe_o3 |> prep() |> bake(train_data) |> _[1:100,] |> DT::datatable()
```

## Tworzenie modelu

```{r}
lr_mod <- 
  logistic_reg(penalty = 0.0001, mixture = 1) |> 
  set_engine("glmnet")
```

## Workflow oraz trening
```{r}
final_model <- workflow() |> 
  add_model(lr_mod) |> 
  add_recipe(air_recipe_o3) 
```

```{r}
air_fit <- 
  final_model |> 
  fit(data = train_data)
```

Oraz wyniki treningu:
```{r}
air_fit |> 
  extract_fit_parsnip() |> 
  tidy()
```

# Prognozy
```{r}
predictions <- predict(air_fit, test_data, type = "prob")
```
```{r}
#| echo: false
predictions
```

## Krzywa roc
```{r}
pred_test <- 
  augment(air_fit, test_data) |> 
  select(.pred_class:date, ozone)

pred_test  |> 
  roc_curve(truth = ozone, .pred_Niskie) |> 
  autoplot()
```


Wartość roc

Można uzyskać więcej 0.96

```{r}
pred_test |> 
  roc_auc(truth = ozone, .pred_Niskie)
```

Macierz błędów
```{r}
pred_test |> conf_mat(truth = ozone, estimate = .pred_class) 
```

# Metoda lasu losowego i walidacje krzyżowe

Zaczniemy od utworzenia modelu lasu losowego oraz ustawienia ziarna. Użyjemy tego samego recipie co wcześniej. 
cw 4.6 Dodatkowo dodajemy hiperparametry

```{r}

set.seed("123")

rf_mod <- 
  rand_forest(trees = tune(),
              mtry = tune()) |> 
  set_engine("ranger") |> 
  set_mode("classification")

```

Tworzenie siatki oraz workflow.
```{r}
mtry_param <- finalize(mtry(), x = train_data)
rf_mod

siatka <- grid_regular(mtry_param,
                       trees(), 
                       levels = 3)
siatka
siatka |> count(mtry)


rf_wflow <- workflow() |> 
  add_model(rf_mod) |> 
  add_recipe(air_recipe_o3) 

miary_oceny <-
  yardstick::metric_set(
    accuracy,
    mcc,
    npv,
    roc_auc)
```

## Walidacje dla lasu losowego
### Walidacja krzyżowa V-fold



```{r}
set.seed("123")
air_rf_folds = vfold_cv(train_data, v=5)

air_fit_rf_folds <-
  rf_wflow |>
  tune_grid(
    resamples = air_rf_folds,
    grid = siatka,
    metrics = miary_oceny
  )

air_fit_rf_folds |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)

air_fit_rf_folds |> select_best(metric = "accuracy")

air_fit_rf_folds_best <- rf_wflow |> finalize_workflow(air_fit_rf_folds |> select_best(metric = "accuracy"))

air_fit_rf_folds_final <- air_fit_rf_folds_best |> last_fit(split = data_split)

air_fit_rf_folds_final |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)

```

### Walidacja krzyżowa V-fold powtarzana

```{r}
set.seed("123")
air_rf_folds_rep = vfold_cv(train_data, v=5, repeats = 5)

air_fit_rf_folds_rep <-
  rf_wflow |>
  tune_grid(
    resamples = air_rf_folds_rep,
    grid = siatka,
    metrics = miary_oceny
  )

air_fit_rf_folds_rep |> select_best(metric = "accuracy")

air_fit_rf_folds_rep_best <- rf_wflow |> finalize_workflow(air_fit_rf_folds_rep |> select_best(metric = "accuracy"))

air_fit_rf_folds_rep_final <- air_fit_rf_folds_rep_best |> last_fit(split = data_split)

air_fit_rf_folds_rep_final |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)
```

### Walidacja krzyżowa Monte Carlo

```{r}
set.seed("123")
air_rf_mc = mc_cv(train_data, prop=9/10, times = 5)

air_fit_rf_mc <-
  rf_wflow |>
  tune_grid(
    resamples = air_rf_mc,
    grid = siatka,
    metrics = miary_oceny
  )

air_fit_rf_mc |> select_best(metric = "accuracy")

air_fit_rf_mc_best <- rf_wflow |> finalize_workflow(air_fit_rf_mc |> select_best(metric = "accuracy"))

air_fit_rf_mc_final <- air_fit_rf_mc_best |> last_fit(split = data_split)

air_fit_rf_mc_final |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)
```

### Bootstraping

```{r}
set.seed("123")
air_rf_bootstrap <- bootstraps(train_data, times = 5)

air_fit_rf_bootstrap <-
  rf_wflow |>
  tune_grid(
    resamples = air_rf_bootstrap,
    grid = siatka,
    metrics = miary_oceny
  )

air_fit_rf_bootstrap |> select_best(metric = "accuracy")

air_fit_rf_bootstrap_best <- rf_wflow |> finalize_workflow(air_fit_rf_bootstrap |> select_best(metric = "accuracy"))

air_fit_rf_bootstrap_final <- air_fit_rf_bootstrap_best |> last_fit(split = data_split)

air_fit_rf_bootstrap_final |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)

```

### Zapisanie wyników oraz wykres

```{r}
rf_wyniki <- bind_cols(
  c(rep("Vfold", 3), rep("Vfold-repeated",3), rep("Monte carlo cv",3), rep("Bootstrap", 3)),
  
  bind_rows(
    air_fit_rf_folds_final |> collect_metrics(),
    air_fit_rf_folds_rep_final |> collect_metrics(),
    air_fit_rf_mc_final |> collect_metrics(),
    air_fit_rf_bootstrap_final |> collect_metrics() 
  ))|> tibble()

rf_wyniki <- rename(rf_wyniki, nazwa_metody = ...1)
rf_wyniki
```

```{r}
wykres_rf <- ggplot(rf_wyniki, aes(x = nazwa_metody, y = .estimate, fill = nazwa_metody)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = round(.estimate, 3)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3) +
  labs(title = "Las losowy - Porównanie wyników w zależności od metody walidacji",
       y = "Wartość metryki",
       x = " ",
       fill = "Metoda walidacji") +
  facet_wrap(~.metric, scales = "free_y") +
  theme_bw() +
  theme(axis.text.x = element_blank())
wykres_rf
```

## Walidacje dla regresji logistycznej

### Walidacja krzyżowa V-fold

```{r}
vfold_cv_resample = vfold_cv(train_data, v=10)
vfold_cv_resample
vfold_cv_resample$splits[[1]] %>% analysis() %>% dim()

air_fit_rs <- final_model |> fit_resamples(vfold_cv_resample)
air_fit_rs |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)
```

### Walidacja krzyżowa V-fold powtarzana
```{r}

vfold_cv_resample_rep = vfold_cv(train_data, v=10, repeats = 5)
vfold_cv_resample_rep
vfold_cv_resample_rep$splits[[1]] %>% analysis() %>% dim()

air_fit_rs_rep <- final_model |> fit_resamples(vfold_cv_resample_rep)
air_fit_rs_rep |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)
```

### Walidacja krzyżowa Monte Carlo
```{r}
mc_cv_resample = mc_cv(train_data, prop=9/10, times = 10)
mc_cv_resample
mc_cv_resample$splits[[1]] %>% analysis() %>% dim()

air_fit_rs_mc <- final_model |> fit_resamples(mc_cv_resample)
air_fit_rs_mc |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)
```

### Bootstraping
```{r}
air_rs_bootstrap <- bootstraps(train_data, times = 10)
air_rs_bootstrap
air_rs_bootstrap$splits[[1]] %>% analysis() %>% dim()

air_fit_rs_bootstrap <- final_model |> fit_resamples(air_rs_bootstrap)
air_fit_rs_bootstrap |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)
```

### Zapisanie wyników oraz wykres
```{r}
log_reg_wyniki <- bind_cols(
  c(rep("Vfold", 3), rep("Vfold-repeated",3), rep("Monte carlo cv",3), rep("Bootstrap",3)),

bind_rows(
  air_fit_rs |> collect_metrics() ,
  air_fit_rs_rep |> collect_metrics() ,
  air_fit_rs_mc |> collect_metrics(),
  air_fit_rs_bootstrap |> collect_metrics()
) )|> tibble()

log_reg_wyniki <- rename(log_reg_wyniki, nazwa_metody = ...1)
log_reg_wyniki
```

```{r}
wykres_log_reg <- ggplot(log_reg_wyniki, aes(x = nazwa_metody, y = mean, fill = nazwa_metody)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = round(mean, 3)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3) +
  labs(title = "Regresja logistyczna - Porównanie wyników w zależności od metody walidacji",
       y = "Wartość metryki",
       x = " ",
       fill = "Metoda walidacji") +
  facet_wrap(~.metric, scales = "free_y") +
  theme_bw() +
  theme(axis.text.x = element_blank())
wykres_log_reg
```

## Porównanie danych

```{r}
library(patchwork)
(wykres_rf + coord_cartesian(ylim = c(0, 1.1)))/(wykres_log_reg + coord_cartesian(ylim = c(0, 1.1)))
```